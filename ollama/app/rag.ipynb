{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model = 'EEVE-Korean-10.8B:latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론이죠, 도움이 되고 존중하는 조수로서 여러분의 질문에 최선을 다해 답변해드리겠습니다! 정확하고 관련 있는 답변을 제공하기 위해 노력하면서 동시에 안전하고 사회적으로 편견이 없는 반응을 보장하겠습니다. 궁금한 점이나 우려사항이 있으시면 언제든지 문의해주세요.\\r\\n\\r\\n짧은 대답을 원하신다면 다음과 같습니다:\\r\\n\\r\\n1. \"인공지능 조수로서 저는 여러분을 도와드리기 위해 여기에 있습니다! 질문을 하거나 저에게 과제를 주십시오.\"\\r\\n2. \"저는 AI 어시스턴트로서 정확하고 유용한 정보를 제공하기 위해 노력합니다. 궁금한 점이나 우려사항이 있으면 언제든지 물어보세요!\"\\r\\n3. \"긍정적이고 참여적인 태도를 유지하며 여러분을 돕기 위해 최선을 다하겠습니다. 무엇이든 도와드릴 준비가 되어 있습니다.\"\\r\\n4. \"당신의 질문을 듣고 있으며, 답변을 드리기 위해 노력하고 있습니다. 조금만 기다려 주세요.\"\\r\\n5. \"AI 조수로서 제가 할 수 있는 모든 방법으로 여러분에게 도움이 되고자 합니다. 궁금한 점이나 우려사항이 있으면 알려주세요!\"\\r\\n6. \"여러분을 지원하고 최선을 다해 여러분의 필요를 충족시키기 위해 여기에 있습니다. 무엇이든 도와드릴 준비가 되어 있습니다.\"\\r\\n7. \"저에게는 항상 질문이 있거나 해결해야 할 문제가 있다면 도움을 줄 준비가 되어 있는 AI 어시스턴트가 있습니다. 망설이지 말고 물어보세요!\"\\r\\n8. \"저는 여러분을 돕기 위해 여기에 있으며, 여러분의 모든 질문과 우려사항을 해결하는 데 최선을 다할 것입니다. 무엇이든 도와드릴 준비가 되어 있습니다.\"\\r\\n9. \"여러분이 저를 의지하는 것이 얼마나 중요한지 알고 있으며, 항상 최선을 다해 여러분을 지원하고자 합니다. 궁금한 점이나 우려사항이 있으면 언제든지 물어보세요!\"\\r\\n10. \"저는 여러분의 AI 어시스턴트로서 정확하고 유용한 정보를 제공하기 위해 노력합니다. 무엇이든 도와드릴 준비가 되어 있으니 망설이지 말고 물어보세요!\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"대답은 짧게 해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://blog.langchain.dev/langgraph/\"\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    "    add_start_index = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the data\n",
    "from langchain_community import embeddings\n",
    "\n",
    "embedding = embeddings.ollama.OllamaEmbeddings(\n",
    "    # model=\"nomic-embed-text:latest\"\n",
    "    model = \"EEVE-Korean-10.8B:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = all_splits,\n",
    "    embedding = embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vectorstore.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = {\"k\": 6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='some state)More controlled human-in-the-loop workflowsMulti-agent workflowsIf any of these resonate with you, please feel free to add an example notebook in the LangGraph repo, or reach out to us at hello@langchain.dev for more involved collaboration!', metadata={'language': 'en', 'source': 'https://blog.langchain.dev/langgraph/', 'start_index': 11185, 'title': 'LangGraph'}),\n",
       " Document(page_content='Tags\\nBy LangChain\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\nYou might also like\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReflection Agents\\n\\n\\nagents\\n6 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPlan-and-Execute Agents\\n\\n\\nBy LangChain\\n5 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Week of 2/19] LangChain Release Notes\\n\\n\\nBy LangChain\\n1 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients and employees\\n\\n\\nBy LangChain\\n3 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Week of 2/5] LangChain Release Notes\\n\\n\\nBy LangChain\\n4 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain Partners with CommandBar on their Copilot User Assistant\\n\\n\\nBy LangChain\\n2 min read\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            Â© LangChain Blog 2024', metadata={'language': 'en', 'source': 'https://blog.langchain.dev/langgraph/', 'start_index': 11439, 'title': 'LangGraph'}),\n",
       " Document(page_content='class State(TypedDict):\\n    input: str\\n    all_actions: Annotated[List[str], operator.add]', metadata={'language': 'en', 'source': 'https://blog.langchain.dev/langgraph/', 'start_index': 5400, 'title': 'LangGraph'}),\n",
       " Document(page_content='class AgentState(TypedDict):', metadata={'language': 'en', 'source': 'https://blog.langchain.dev/langgraph/', 'start_index': 9561, 'title': 'LangGraph'}),\n",
       " Document(page_content='from langchain_core.agents import AgentAction, AgentFinish\\nfrom langchain_core.messages import BaseMessage\\nimport operator', metadata={'language': 'en', 'source': 'https://blog.langchain.dev/langgraph/', 'start_index': 8526, 'title': 'LangGraph'}),\n",
       " Document(page_content='from typing import TypedDict, List, Annotated\\nimport Operator', metadata={'language': 'en', 'source': 'https://blog.langchain.dev/langgraph/', 'start_index': 5336, 'title': 'LangGraph'})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.get_relevant_documents(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"You must answer in Korean.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "contextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대형 모델이란 언어 이해와 생성 능력을 향상시키기 위해 대량의 데이터셋을 학습한 AI 시스템을 의미합니다.\\r\\n\\r\\n예를 들어, LLM은 문맥과 구조를 고려하여 질문에 답하고, 텍스트를 생성하며, 복잡한 작업을 수행하기 위해 자연어 처리(Natural Language Processing, NLP)와 기계학습(Machine Learning, ML) 기술을 사용하는 첨단 AI 시스템입니다. 이 모델들은 대량의 데이터를 학습함으로써 언어 능력을 향상시키고 다양한 분야에서 인간과 같은 수준의 성능을 달성할 수 있습니다.\\r\\n\\r\\n대형 모델은 일반적으로 대규모 사전 훈련된 모델로, 방대한 데이터셋에서 미리 학습되어 새로운 작업이나 도메인에 쉽게 적용될 수 있습니다. 이러한 모델들은 복잡한 작업을 수행하고 인간의 언어 능력을 시뮬레이션하는 데 탁월한 성과를 보여줍니다.\\r\\n\\r\\nLLM 중 대표적인 예시로는 BERT, GPT-3, T5 등이 있으며, 이들 모두 자연어 처리 분야에서 중요한 발전을 이루었습니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "contextualize_q_chain.invoke(\n",
    "    {\n",
    "        \"chat_history\":[\n",
    "            HumanMessage(content=\"What does LLM stand for?\"),\n",
    "            AIMessage(content=\"Large Language model\")\n",
    "        ],\n",
    "        \"question\" : \"What is meant by large?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You must answer in Korean.\\\n",
    "대답한 최대한 짧게 만들어줘\\\n",
    "\n",
    "{context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextualize_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context = contextualize_question | retriver | format_docs\n",
    "    )\n",
    "    | qa_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"what is LangGraph?\"\n",
    "ai_msg = rag_chain.invoke(\n",
    "    {\n",
    "        \"question\": question,\n",
    "        \"chat_history\": chat_history\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangGraph는 인간-루프 워크플로우(human-in-the-loop workflows), 다중 에이전트 워크플로우(multi-agent workflows)를 포함한 다양한 고급 기능을 지원하는 랭체인(LangChain)의 확장판입니다.\\r\\n\\r\\nLangGraph는 LangChain 생태계 내에서 작업 흐름을 관리하고 조정하는 데 사용되며, 언어 모델을 사용하여 여러 에이전트를 포함하고 복잡한 작업을 처리하는 능력을 제공합니다. 이는 워크플로우를 설정하고 관리하는 데 있어 더 세밀한 제어와 유연성을 가능하게 합니다.\\r\\n\\r\\n예를 들어, LangGraph를 통해 사용자는 기존 LangChain 에이전트들과 함께 새로운 노드를 생성하여 맞춤형 워크플로를 만들 수 있습니다. 또한 이러한 워크플로에서 다양한 언어 모델과 서비스를 활용할 수 있어 더욱 정교하고 강력한 솔루션을 개발할 수 있게 됩니다.\\r\\n\\r\\nLangGraph는 랭체인 팀 및 커뮤니티와의 협업 기회를 제공하며, 사용자는 LangGraph 저장소에 예제 노트북을 추가하거나 hello@langchain.dev로 더 깊은 협업을 제안할 수도 있습니다.\\r\\n\\r\\n요약하자면, LangGraph는 고급 기능 세트를 갖춘 강력한 도구로서, 사용자가 여러 에이전트와 복잡한 워크플로우를 포함하는 맞춤형 언어 모델 기반 시스템을 구축할 수 있게 합니다.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question), ai_msg\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangGraph는 랭체인(LangChain)의 확장판으로, 인간-루프 워크플로우(human-in-the-loop workflows), 다중 에이전트 워크플로우(multi-agent workflows)를 포함한 다양한 고급 기능을 지원합니다.\\r\\n\\r\\nLangGraph는 LangChain 생태계 내에서 작업 흐름을 관리하고 조정하는 데 사용되며, 언어 모델을 사용하여 여러 에이전트를 포함하고 복잡한 작업을 처리할 수 있게 합니다. 이는 워크플로우 설정을 위한 더 세밀한 제어와 유연성을 제공합니다.\\r\\n\\r\\n예를 들어, LangGraph를 통해 사용자는 기존 LangChain 에이전트들과 함께 새로운 노드를 생성하여 맞춤형 워크플로를 만들 수 있습니다. 또한 이러한 워크플로에서 다양한 언어 모델과 서비스를 활용할 수 있어 더욱 정교하고 강력한 솔루션을 개발할 수 있게 됩니다.\\r\\n\\r\\nLangGraph는 랭체인 팀 및 커뮤니티와의 협업 기회를 제공하며, 사용자는 LangGraph 저장소에 예제 노트북을 추가하거나 hello@langchain.dev로 더 깊은 협업을 제안할 수도 있습니다.\\r\\n\\r\\n요약하자면, LangGraph는 고급 기능 세트를 갖춘 강력한 도구로서, 사용자가 여러 에이전트와 복잡한 워크플로우를 포함하는 맞춤형 언어 모델 기반 시스템을 구축할 수 있게 합니다.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_question = \"What is it used for?\"\n",
    "\n",
    "rag_chain.invoke(\n",
    "    {\n",
    "        \"question\": second_question,\n",
    "        \"chat_history\": chat_history\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
